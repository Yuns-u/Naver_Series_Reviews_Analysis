{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testrank_naverseries_review.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPPCTRsMMFiKWfl2Nddeetu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuns-u/Naver_Series_Reviews_Analysis/blob/main/testrank_naverseries_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuMrjORHn8rI"
      },
      "source": [
        "# 목표\n",
        "한국어 Glove 모델을 이용하여 문장들을 임베딩 한 뒤, 임베딩 결과로 RANK를 메겨 상위 3개의 문장을 문서의 추출요약으로 선정."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-8p7g69pQPf"
      },
      "source": [
        "pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8qs5RQ7pWSd"
      },
      "source": [
        "import re\n",
        "import konlpy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFW-uofMoGTB"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIxDAp5loH3l"
      },
      "source": [
        "#데이터 불러오기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYwOKB8iugIB"
      },
      "source": [
        "df = pd.read_csv('IOS_ReviewData_naverseries_2.csv', engine='python')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oYg33RevUfX"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhrQiZBwoDNE"
      },
      "source": [
        "# 전처리: 한글 이외의 corpus 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8nsuJBYn5Mp"
      },
      "source": [
        "def cleaning(text): \n",
        "  repl ='' \n",
        "  pattern = '([ㄱ-ㅎㅏ-ㅣ]+)' # 자음, 모음 제거 \n",
        "  text = re.sub(pattern= pattern, repl=repl, string=text) \n",
        "  #pattern = '[^\\w\\s]' # 특수기호 제거 \n",
        "  pattern = '[^가-히\\s]' # 특수기호 제거 \n",
        "  text = re.sub(pattern= pattern, repl=repl, string=text) \n",
        "  pattern = '<[^>]*>' # html 제거 \n",
        "  text = re.sub(pattern = pattern, repl='',string=text) \n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Ss75MZpIXC"
      },
      "source": [
        "df['Reviews'] = df['Reviews'].map(lambda x: cleaning(x))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQcT3UiM9xIn"
      },
      "source": [
        "# 불용어 정의\n",
        "stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','을','으로','자','에','와','한','하다','요', '아니',\n",
        "           '해서','에서','제','신건','아니','저기','주세요','해','서','되는','논','여','저','로','으로','오','고','랑','이랑',\n",
        "           '합니다','부터','\\n','\\n\\n','왜','입니다','에도','하고','만','다','너무','했는데','수','것','때','거','하는','있는',\n",
        "           '하는']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnepCtcc7MuK"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "tokenizer = Okt()\n",
        "\n",
        "tokenized=[]\n",
        "for sentence in df['Reviews']:\n",
        "    temp = tokenizer.nouns(sentence) # 토큰화morphs를 쓸 때보다 명사만 추출했을 때 더 잘 파악됨. 한국어 표제어 추출이 어려움.\n",
        "    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n",
        "    tokenized.append(temp)\n",
        "\n",
        "print(tokenized[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DRKkkMDmk2y"
      },
      "source": [
        "df['Tokens'] = tokenized\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdnjuCiY_Zaf"
      },
      "source": [
        "# 리뷰 길이 분포 확인\n",
        "print('키워드의 최대 길이 :',max(len(l) for l in tokenized))\n",
        "print('키워드의 평균 길이 :',sum(map(len, tokenized))/len(tokenized))\n",
        "plt.hist([len(s) for s in tokenized], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOZGMsmlpYG7"
      },
      "source": [
        "#전처리된 텍스트들의 길이 분포 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k-AaRG4pcc_"
      },
      "source": [
        "text_len = [len(s.split()) for s in df['Reviews']]\n",
        "keys_len = [len(s) for s in df['Tokens']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzioT66rpbX2"
      },
      "source": [
        "print('원문의 최소 길이: ', np.min(text_len))\n",
        "print('원문의 최대 길이: ', np.max(text_len))\n",
        "print('원문의 평균 길이: ', np.mean(text_len))\n",
        "print('키워드의 최소 길이: ', np.min(keys_len))\n",
        "print('키워드의 최대 길이: ', np.max(keys_len))\n",
        "print('키워드의 평균 길이: ', np.mean(keys_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDKe4NIVqJ2F"
      },
      "source": [
        "# 박스플롯으로 살펴보기\n",
        "\n",
        "# 요약문 텍스트 길이 분포 박스플롯\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(keys_len)\n",
        "plt.title('Text Length of keynouns')\n",
        "plt.show()\n",
        "\n",
        "# 원문 텍스트 길이 분포 박스플롯\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('Text Length of Original Text')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la49ydq2qU3N"
      },
      "source": [
        "# 히스토그램으로 살펴보기\n",
        "\n",
        "# 요약문 텍스트 길이 분포 히스토그램\n",
        "plt.title('Text Length of keynouns')\n",
        "plt.hist(keys_len, bins=40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('the number of samples')\n",
        "plt.show()\n",
        "\n",
        "# 원문 텍스트 길이 분포 히스토그램\n",
        "plt.title('Text Length of Original Text')\n",
        "plt.hist(text_len, bins=40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('the number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pM2iG-DqdXf"
      },
      "source": [
        "원문 텍스트는 대체적으로 25이하의 길이를 가지며 평균적으로 13의 길이를 가지고 있다.\n",
        "\n",
        "\n",
        "키워드의 경우 대체적으로 20이하의 길이를 가지며 평균 길이는 13이다. \n",
        "\n",
        "여기에서 패딩의 길이는 평균 길이정도인 25와 13으로 잡아주기로 했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1MlerFKrTqR"
      },
      "source": [
        "text_max_len =25\n",
        "keys_max_len =13"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrl6pjC3rc3w"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if (len(s.split()) <= max_len):\n",
        "      cnt = cnt+1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt/len(nested_list))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rixc9yhrd3y"
      },
      "source": [
        "below_threshold_len(text_max_len, df['Reviews'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmchvmLcrvCC"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if (len(s) <= max_len):\n",
        "      cnt = cnt+1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt/len(nested_list))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrsNFBAxripK"
      },
      "source": [
        "below_threshold_len(keys_max_len, df['Tokens'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFCYzracr4HV"
      },
      "source": [
        " 정해준 최대 길이보다 큰 샘플들은 연산의 수월성을 위하여 제거하고자 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1cP8BoGr49o"
      },
      "source": [
        "df = df[df['Reviews'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
        "df = df[df['Tokens'].apply(lambda x: len(x) <= keys_max_len)]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ui92vNrvCPn"
      },
      "source": [
        "#줄면서 없어진 것은 결측치로 없애주기\n",
        "df['Tokens'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv0uUy1-sIv8"
      },
      "source": [
        "print('전체 데이터의 수: ',len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8dS8-gmslXM"
      },
      "source": [
        "test_num = int(len(df)*0.2)\n",
        "test_num\n",
        "#전체데이터의 20%는 64개라고 할 수 있다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAYKnz3lupWD"
      },
      "source": [
        "# train, test data 분류 \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['Reviews']], df['Tokens'], train_size = 0.8, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNW4OD8wuyII"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdympXRtuy_a"
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5BIlRpiu58b"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLz_Q9J_2ag1"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1frg9TQ5Ji-"
      },
      "source": [
        "df['Reviews'].to_json('ios_reviews.json',orient='columns',force_ascii=False)\n",
        "#로컬환경으로 다운로드받기\n",
        "from google.colab import files\n",
        "files.download('ios_reviews.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-R53933yk3"
      },
      "source": [
        "from gensim.summarization.summarizer import summarize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9BRwsg76m1W"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('ios_reviews.json', 'r', encoding='utf-8-sig') as f:\n",
        "    comment = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hrhMV4N-Oit"
      },
      "source": [
        "review_list = np.array(df['Reviews'].tolist())\n",
        "review_list[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOheU07e8OgO"
      },
      "source": [
        "key_sentence = {}\n",
        "\n",
        "for res in review_list:\n",
        "    review = comment[res]\n",
        "    su = summarize(review, word_count=5)\n",
        "    su = re.sub('\\n', ' ',su)\n",
        "    if len(su) == 0:\n",
        "        continue\n",
        "    key_sentence[res] = su"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOIMnW17As81"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swq3j5_HBIoY"
      },
      "source": [
        "#토큰화된 문서들을 입력받아 토큰을 센 뒤 관련된 속성을 가진 데이터프레임을 return\n",
        "def word_count(docs):\n",
        "  #전체 코퍼스에서 단어 빈도 카운트\n",
        "  word_counts = Counter()\n",
        "\n",
        "  #단어가 존재하는 문서의 빈도 카운트, 단어가 한 번 이상 존재하면 1을 더한다.\n",
        "  word_in_docs = Counter()\n",
        "\n",
        "  #전체 문서의 개수\n",
        "  total_docs = len(docs)\n",
        "\n",
        "  for doc in docs:\n",
        "    word_counts.update(doc)\n",
        "    word_in_docs.update(set(doc))\n",
        "\n",
        "  temp = zip(word_counts.keys(), word_counts.values())\n",
        "  wc = pd.DataFrame(temp, columns=['word','count'])\n",
        "\n",
        "  #단어 순위\n",
        "  #method='first':같은 값의 경우 먼저 나온 요소를 우선\n",
        "  wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
        "  total = wc['count'].sum()\n",
        "\n",
        "  #코퍼스 내 단어의 비율\n",
        "  wc['percent'] = wc['count'].apply(lambda x: x/ total)\n",
        "  wc = wc.sort_values(by='rank')\n",
        "\n",
        "  #누적 비율\n",
        "  #cumsum() : cumulative sum\n",
        "  wc['cul_percent'] = wc['percent'].cumsum()\n",
        "\n",
        "  temp2 = zip(word_in_docs.keys(), word_in_docs.values())\n",
        "  ac = pd.DataFrame(temp2, columns=['word','word_in_docs'])\n",
        "  wc = ac.merge(wc, on='word')\n",
        "\n",
        "  #전체 문서 중 존재하는 비율\n",
        "  wc['word_in_docs_percent'] = wc['word_in_docs'].apply(lambda x: x/total_docs)\n",
        "\n",
        "  return wc.sort_values(by='rank')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_-aySafBKgu"
      },
      "source": [
        "wc = word_count(df['Tokens'])\n",
        "wc.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QfRq5nnBS14"
      },
      "source": [
        "wc.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJlMZmieBWZr"
      },
      "source": [
        "#토큰 순위에 따른 퍼센트 누적 분포 그래프\n",
        "import seaborn as sns\n",
        "\n",
        "sns.lineplot(x='rank', y='cul_percent', data=wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ4IOzecBX9v"
      },
      "source": [
        "# ----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQY4cmwmArjD"
      },
      "source": [
        "pip install gensim --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl2rLzbXAw7C"
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9C-77zWA1gL"
      },
      "source": [
        "model = Word2Vec(sentences = tokenized, window = 3, min_count = 2, workers = 4, sg = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLadmoMTA4HZ"
      },
      "source": [
        "model.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bzzNJ8lA684"
      },
      "source": [
        "model.wv.most_similar(\"쿠키\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOjsgLgJA-03"
      },
      "source": [
        "model.wv.most_similar(\"어디\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}